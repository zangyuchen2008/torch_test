{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('yuchen': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5a9a2815de8b294c6d96af5182196e1874f81478d929f147fe04ad9cb4ddd4e4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel,AutoConfig,AutoTokenizer\n",
    "from torch import nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import  dataloader\n",
    "from transformers import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import  tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_disdbert():\n",
    "    config = AutoConfig.from_pretrained('/data/yuchen/projects/transformers_test/model/distilbert/config.json')\n",
    "    model = AutoModel.from_config(config)\n",
    "    # tokenizer = AutoTokenizer.from_pretrained('/data/yuchen/projects/test/transformers_test/model/distilbert')\n",
    "    # inputs = tokenizer('hello world',return_tensors='pt')\n",
    "    return model\n",
    "\n",
    "class Classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classification,self).__init__()\n",
    "        self.distilbert = load_disdbert()\n",
    "        self.ffn = nn.Linear(768,2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self,inputs):\n",
    "        cls = self.distilbert(**inputs)['last_hidden_state'][:,0,:]\n",
    "        cls =  self.ffn(cls)\n",
    "        # cls = self.softmax(cls)\n",
    "        return cls\n",
    "\n",
    "def loss(score,label):\n",
    "    loss = nn.functional.cross_entropy(score,label)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=2\n",
    "imdb = pd.read_csv('/data/yuchen/projects/transformers_test/data/IMDB Dataset.csv')\n",
    "imdb.sentiment = imdb.sentiment.apply(lambda x: 0 if x == 'positive' else 1)#.astype(float)\n",
    "imdb.review = imdb.review.astype(str)\n",
    "data = list(zip(imdb.review.to_list(),imdb.sentiment.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = dataloader.DataLoader(data[:-10000],batch_size=BATCH_SIZE,shuffle=True)\n",
    "valid_dl = dataloader.DataLoader(data[-1000:],batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  Classification().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained('/data/yuchen/projects/transformers_test/model/distilbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 500/500 [00:13<00:00, 36.93it/s]0.48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid_result = []\n",
    "for valid_data, label in tqdm(valid_dl):\n",
    "    inputs = tokenizer(list(valid_data),return_tensors='pt',padding='max_length',max_length=512,truncation=True).to(torch.cuda.current_device())\n",
    "    logits = model(inputs)\n",
    "    pro = nn.functional.softmax(logits,dim=1)\n",
    "    pre = pro.argmax(dim=1)\n",
    "    pre = pre.detach().cpu().numpy()\n",
    "    accuracy_score(label,pre)\n",
    "    valid_result.append(accuracy_score(label,pre))\n",
    "print(sum(valid_result) / len(valid_result))\n",
    "    # break"
   ]
  }
 ]
}